# Детекция и сглаживание траекторий людей на видео (YOLO + Kalman Filter)

## Описание

В рамках выполнения тестового задания на позицию Junior Data Scientist я разработал систему для детекции и отслеживания людей на видео.  В качестве основного инструмента детекции я выбрал модель YOLO, а для сглаживания траекторий движения объектов и повышения стабильности визуализации — фильтр Калмана.

**Реализованные возможности:**

*   **Детекция людей:** На каждом кадре видео обнаруживаются люди с использованием предобученной модели YOLO.
*   **Сглаживание траекторий:** Для улучшения плавности движения и устранения "дрожания" bounding box'ов я применил фильтр Калмана.
*   **Мультипроцессинг:** Для ускорения обработки видео я использовал модуль `multiprocessing`, что позволяет обрабатывать кадры параллельно.
*   **Soft-NMS:**  Для уменьшения количества перекрывающихся bounding box'ов, соответствующих одному и тому же человеку, я использовал алгоритм Soft-NMS.
*   **Настраиваемые параметры:** Все основные параметры (пути к файлам, модель, количество процессов, пороги и т.д.) можно легко изменить в начале скрипта `main.py`.
*   **Логирование:**  Я добавил подробное логирование, чтобы было удобно отслеживать процесс выполнения и диагностировать возможные проблемы.
*   **Выбор формата выходного видео:**  Есть возможность выбрать кодек для выходного видео.
*   **Обработка ошибок:**  В коде предусмотрена обработка ошибок, таких как отсутствие входного файла или невозможность его открыть.
*   **Ансамблирование моделей** (опционально, закомментировано в коде): добавил возможность использовать сразу несколько моделей YOLO

## Требования

Для работы проекта необходимы:

*   Python 3.7+ (я рекомендую 3.9 или 3.10, так как с ними, как правило, меньше проблем с совместимостью библиотек).
*   Библиотеки:
    *   `opencv-python`
    *   `ultralytics` (для YOLO)
    *   `filterpy` (для фильтра Калмана)
    *   `numpy`
    *   `torch`
    *  `typing-extensions`
    *   `psutil`
     *  `py-cpuinfo`
     *   `pandas`
     *   `seaborn`
     *   `tqdm`
     *  `requests`
     * `matplotlib`

## Установка

1.  **Клонирование репозитория:**

    ```bash
    git clone https://github.com/maxlyara1/crowd_detection_task
    cd crowd_detection_task
    ```

2.  **Создание виртуального окружения (настоятельно рекомендуется):**

    *   **`venv`:**

        ```bash
        python3 -m venv venv  # Создание
        source venv/bin/activate  # Активация (macOS/Linux)
        # venv\Scripts\activate   # Активация (Windows)
        ```

3.  **Установка зависимостей:**

    ```bash
    pip install -r requirements.txt
    ```
    Либо, если возникнут сложности:
     ```bash
      pip install opencv-python ultralytics filterpy numpy torch typing-extensions psutil py-cpuinfo pandas seaborn tqdm requests matplotlib
     ```

## Использование

1.  **Поместите видеофайл `crowd.mp4` в ту же директорию, что и скрипт `main.py`.**  Или укажите путь к вашему видеофайлу в переменной `input_file` в начале `main.py`.

2.  **Настройте параметры (при необходимости):**  Откройте `main.py` и измените значения переменных в блоке `if __name__ == "__main__":`:
    *   `input_file`: Путь к входному видео.
    *   `output_file`: Путь к выходному видео.
    *   `model_paths`: Список путей к моделям YOLO (`.pt`). По умолчанию `yolo11m.pt`.  Для ансамблирования укажите несколько.
    *   `num_processes`:  Количество процессов (None = автоопределение). *Рекомендуется начать с 2 и увеличивать, если нужно.*
    *   `iou_threshold`: Порог IoU для NMS/Soft-NMS и фильтра Калмана.
    *   `use_soft_nms`: Использовать Soft-NMS (`True`) или стандартный NMS (`False`).
    *   `output_format`: Кодек выходного видео ('mp4v', 'avc1', 'xvid').

3.  **Запустите скрипт:**

    ```bash
    python main.py
    ```

4.  **Результат:**  В той же директории будет создан выходной видеофайл (`output.mp4`) с bounding box'ами вокруг людей.  В консоли будет выводиться информация о прогрессе.

## Структура кода

*   **`main.py`:**
    *   `apply_kalman_filter(bbox, kf, dt)`: Применяет фильтр Калмана.
    *   `initialize_kalman_filter()`: Создает фильтр Калмана.
    *   `process_frame(...)`: Обрабатывает один кадр.
    *   `group_detections(...)`: Группирует перекрывающиеся bounding box'ы (для ансамблирования).
    *   `calculate_iou(box1, box2)`: Вычисляет IoU.
    *   `soft_nms(...)`: Реализует Soft-NMS.
    *   `detect_and_track_parallel(...)`: Главная функция (загрузка видео, моделей, мультипроцессинг, обработка, запись).

## Оптимизации

Я реализовал следующие оптимизации:

*   **Мультипроцессинг:** Параллельная обработка кадров.
*   **Пакетная обработка:**  `imap_unordered` обрабатывает кадры эффективно.
*   **Soft-NMS:** Улучшает качество детекции.
*   **Фильтр Калмана:**  Сглаживает траектории.
*   **Динамический `dt`:**  Учитывается реальное время между кадрами.

## Возможные улучшения

*   **Более продвинутое ансамблирование:**  Вместо простого усреднения можно использовать более сложные методы.
*   **Трекинг:**  Внедрение *полноценного* алгоритма трекинга (ByteTrack, DeepSORT) *значительно* улучшит качество, особенно при перекрытиях.
*   **Дообучение (fine-tuning):** Дообучение модели на данных, более близких к реальным условиям использования системы, может повысить точность.
*  **Использование Yolo-NAS**

Output: https://drive.google.com/file/d/1VomlS6SB5bSw_4QUkF27EMPDEmn5UDtM/view?usp=sharing

## Автор

Максим Ляра Витальевич