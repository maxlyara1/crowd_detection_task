# Детекция и сглаживание траекторий людей на видео (YOLO + Kalman Filter)

## Описание

В рамках выполнения тестового задания на позицию Junior Data Scientist я разработал систему для детекции и отслеживания людей на видео. В качестве основного инструмента детекции я выбрал модель YOLO, а для сглаживания траекторий движения объектов и повышения стабильности визуализации — фильтр Калмана.

**Реализованные возможности:**

*   **Детекция людей:** На каждом кадре видео обнаруживаются люди с использованием предобученной модели YOLO.
*   **Сглаживание траекторий:** Для улучшения плавности движения и устранения "дрожания" bounding box'ов я применил фильтр Калмана.
*   **Мультипроцессинг:** Для ускорения обработки видео я использовал модуль `multiprocessing`, что позволяет обрабатывать кадры параллельно.
*   **Оптимизация памяти:** Обработка видео выполняется порциями, что позволяет эффективно обрабатывать длинные видео без загрузки их целиком в память.
*   **Soft-NMS:**  Для уменьшения количества перекрывающихся bounding box'ов, соответствующих одному и тому же человеку, я использовал алгоритм Soft-NMS.
*   **Настраиваемые параметры:** Все основные параметры можно настроить через аргументы командной строки или изменить значения по умолчанию.
*   **Логирование:**  Я добавил подробное логирование, чтобы было удобно отслеживать процесс выполнения и диагностировать возможные проблемы.
*   **Стабильная видеозапись:** Сохранение порядка кадров обеспечивает плавное и стабильное выходное видео.
*   **Обработка ошибок:**  В коде предусмотрена обработка ошибок, таких как отсутствие входного файла или невозможность его открыть.
*   **Ансамблирование моделей:** Возможность использовать сразу несколько моделей YOLO для повышения точности детекции путем комбинирования их предсказаний с последующим применением NMS.

## Требования

Для работы проекта необходимы:

*   Python 3.8+ (требуется для работы с пакетом ultralytics).
*   Библиотеки (с указанием точных версий):
    *   `opencv-python == 4.8.0`
    *   `ultralytics == 8.0.43` (для YOLO)
    *   `filterpy == 1.4.5` (для фильтра Калмана)
    *   `numpy == 1.24.3`
    *   `torch == 2.0.1`
    *   `typing-extensions == 4.5.0`
    *   `matplotlib == 3.7.2`

## Установка

1.  **Клонирование репозитория:**

    ```bash
    git clone https://github.com/maxlyara1/crowd_detection_task
    cd crowd_detection_task
    ```

2.  **Создание виртуального окружения (настоятельно рекомендуется):**

    *   **`venv`:**

        ```bash
        python3 -m venv venv  # Создание
        source venv/bin/activate  # Активация (macOS/Linux)
        # venv\Scripts\activate   # Активация (Windows)
        ```

3.  **Установка зависимостей:**

    ```bash
    pip install -r requirements.txt
    ```
    Либо, если возникнут сложности:
     ```bash
      pip install opencv-python==4.8.0 ultralytics==8.0.43 filterpy==1.4.5 numpy==1.24.3 torch==2.0.1 typing-extensions==4.5.0 matplotlib==3.7.2
     ```

## Использование

Скрипт можно запустить с параметрами командной строки:

```bash
python main.py --input crowd.mp4 --output result.mp4 --models yolo11m.pt --processes 4 --iou 0.4 --soft-nms
```

### Параметры командной строки:

* `--input` - Путь к входному видеофайлу (по умолчанию: "crowd.mp4")
* `--output` - Путь к выходному видеофайлу (по умолчанию: "output.mp4")
* `--models` - Пути к моделям YOLO (для ансамблирования укажите несколько через пробел)
* `--processes` - Количество процессов для параллельной обработки (None = автоопределение)
* `--iou` - Порог IoU для NMS/Soft-NMS и фильтра Калмана
* `--soft-nms` - Флаг для использования Soft-NMS

**Примечание:** Для совместимости всегда используется кодек 'mp4v', который поддерживается большинством систем без дополнительной установки.

### Ансамблирование моделей

Для повышения точности детекции вы можете использовать ансамблирование нескольких моделей YOLO. При ансамблировании каждая модель обрабатывает один и тот же кадр, затем все предсказания объединяются, и к ним применяется NMS для устранения дублирующихся боксов. Это особенно полезно в сложных сценах с перекрытиями.

Пример запуска с ансамблированием:
```bash
python main.py --models yolo11m.pt yolo11l.pt --output ensemble_result.mp4
```

Алгоритм ансамблирования:
1. Каждая модель делает предсказания независимо
2. Все предсказания объединяются в один массив
3. К объединенным предсказаниям применяется NMS для исключения перекрывающихся боксов 
4. Если одна из моделей не обнаружила объекты, используются результаты других моделей
5. Результирующие детекции используются для трекинга

## Структура проекта

*   `main.py`: Основной скрипт с реализацией детекции и трекинга
*   `requirements.txt`: Файл зависимостей с указанием конкретных версий пакетов
*   `crowd.mp4`: Пример видеофайла для тестирования
*   `README.MD`: Документация проекта

## Оптимизации

Я реализовал следующие оптимизации:

*   **Мультипроцессинг:** Параллельная обработка кадров.
*   **Пакетная обработка:**  Обработка кадров осуществляется батчами для эффективного использования ресурсов.
*   **Soft-NMS:** Улучшает качество детекции.
*   **Фильтр Калмана:**  Сглаживает траектории.
*   **Динамический `dt`:**  Учитывается реальное время между кадрами.

## Оптимизации производительности

1. **Параллельная обработка:** Используется `multiprocessing.Pool` для распределения нагрузки между доступными ядрами процессора.
2. **Постепенная обработка кадров:** Видео обрабатывается порциями вместо загрузки всего файла в память. Это значительно снижает потребление памяти при работе с длинными видео.
3. **Буферизация результатов:** Используется буфер, чтобы сохранять порядок кадров в выходном видео даже при параллельной обработке.
4. **Оптимизация вызовов модели:** Добавлен `with torch.no_grad()` для отключения вычисления градиентов при инференсе.

## Возможные улучшения

*   **Трекинг на основе глубоких признаков:** Можно использовать более продвинутые методы трекинга, основанные на глубоких признаках, а не только на координатах bbox.

*   **Использование YOLO-NAS:** Вместо стандартного YOLO можно использовать YOLO-NAS для следующих преимуществ:
    * Повышение точности детекции на 1.5-2% по сравнению с YOLOv8 при тех же вычислительных затратах
    * Увеличение скорости работы на ~30% благодаря оптимизированной архитектуре нейронной сети
    * Существенное улучшение детекции небольших объектов и объектов в плотных группах, что критично для задачи подсчета людей в толпе
    * Лучшая производительность на CPU за счет используемых оптимизаций

*   **Оптимизация потребления памяти:** Текущая реализация уже оптимизирована для работы с большими видео, но можно дополнительно настроить размер батча кадров в зависимости от доступной памяти.

*   **Автоматический выбор оптимальных параметров:** Можно добавить функциональность для автоматического подбора оптимальных параметров (например, порога IoU) на основе характеристик конкретного видеофайла.

## Автор

Максим Ляра Витальевич